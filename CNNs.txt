# Anexa 1

	Bibliotecile necesare

!pip install keras==2.15.0  
import numpy as np
import tensorflow as tf
from tensorflow.keras import backend as K
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, AveragePooling2D, 
                                     GlobalMaxPooling2D,GlobalAveragePooling2D, 
                                     Activation, Dense, Add, Concatenate, 
                                     BatchNormalization, Lambda, DepthwiseConv2D,     						 Flatten, Dropout)
from tensorflow.keras.preprocessing.image import img_to_array, load_img
from tensorflow.keras.utils import plot_model, to_categorical
from tensorflow.keras.callbacks import *
from tensorflow.keras.optimizers import *
import matplotlib.pyplot as plt
import cv2
import os
import glob
import scipy.io as sio
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder

	Încărcarea bazei de date EMNIST3 din Kaggle

train_dir = '/kaggle/input/emnist3/train'
image_size = (32,32)  # Redimensionarea imaginilor la 32x32
images = []  # Pentru stocarea imaginilor redimensionate
labels = []  # Pentru stocarea etichetelor

# Parcurgerea directoarelor
for subdir, dirs, files in os.walk(train_dir):
    for file in files:
        # Se construiește calea completă a fiecărei imagini
        filepath = os.path.join(subdir, file)
        # Încărcarea și redimensionarea imaginilor
        image = load_img(filepath, target_size=image_size, color_mode='rgb')
        image = img_to_array(image)
        images.append(image)
        # Extragerea etichetei din numele subdirectorului
        label = os.path.basename(subdir)
        labels.append(label)

# Convertire liste în array-uri NumPy
x_train = np.array(images)
y_train = np.array(labels)

# Normalizare date de intrare
x_train = x_train.astype('float32')
x_train /= 255
input_shape=np.shape(x_train)[1:4]
# Convertire etichete în format categorial
label_encoder = LabelEncoder()
y_train = label_encoder.fit_transform(y_train)
y_train = to_categorical(y_train)

# Verificare
print('x_train shape:', x_train.shape)
print('y_train shape:', y_train.shape)
val_dir = '/kaggle/input/emnist3/validation'
image_size = (32,32)  # Redimensionarea imaginilor la la 32x32
images = []  # Pentru stocarea imaginilor redimensionate
labels = []  # Pentru stocarea etichetelor

# Parcurgerea directoarelor
for subdir, dirs, files in os.walk(val_dir):
    for file in files:
        # Se construiește calea completă a fiecărei imagini
        filepath = os.path.join(subdir, file)
        # Încărcarea și redimensionarea imaginilor
        image = load_img(filepath, target_size=image_size, color_mode='rgb')
        image = img_to_array(image)
        images.append(image)
        # Extragerea etichetei din numele subdirectorului
        label = os.path.basename(subdir)
        labels.append(label)

# Convertire liste în array-uri NumPy
x_val = np.array(images)
y_val = np.array(labels)

# Normalizare date de intrare
x_val = x_val.astype('float32')
x_val /= 255

# Convertire etichete în format categorial
label_encoder = LabelEncoder()
y_val = label_encoder.fit_transform(y_val)
y_val = to_categorical(y_val)
# Verificare
print('x_val shape:', x_val.shape)
print('y_val shape:', y_val.shape)

	Încărcarea bazei de date SVHN din TensorFlow
      

!pip install extra-keras-datasets
from extra_keras_datasets import emnist, svhn

reduced=0  #  o valoare pozitivă reprezintă o un număr redus de date de antrenare în cazul problemelor de memorie
dformat='channels_last'

(x_train, y_train), (x_val, y_val) =  svhn.load_data()

if (np.ndim(x_train)==3):   
    x_train=np.reshape(x_train, [np.shape(x_train)[0],np.shape(x_train)[1],np.shape(x_train)[2], 1])
    x_val=np.reshape(x_val, [np.shape(x_val)[0],np.shape(x_val)[1],np.shape(x_val)[2], 1] )
# se adaugă 1 la final pentru a fi compatibil cu kernel-ul din stratul conv2d
# scalare în ([0,1])
x_train = x_train.astype('float32')
x_val = x_val.astype('float32')
x_train /= 255
x_val /=255
inp_chan=np.shape(x_train)[3]
print('Number of input channels in image:', inp_chan)
num_classes=int(np.max(y_train)+1)
num_inputs = np.shape(x_val)[1]
input_shape=np.shape(x_train)[1:4]
if reduced>0:
    Ntr1=reduced
    x_train=x_train[0:Ntr1,:,:,:]
    y_train=y_train[0:Ntr1]
y_train = tf.keras.utils.to_categorical(y_train, num_classes)
y_val = tf.keras.utils.to_categorical(y_val, num_classes)

print('Training samples: ',np.shape(x_train)[0]); print('Esantioane val: ',np.shape(x_val)[0]);
print('Input data shape : ', np.shape(x_train)[1], 'x', np.shape(x_train)[2] )
print('Number of classes: ',num_classes)

	Modelul V-CNN
     
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization
from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, SeparableConv2D  # straturi convolutionale si max-pooling
from tensorflow.keras.optimizers import Adam

#--------------------------  ------------------------------
def create_v_cnn_model(input_shape, num_classes, flat=1, fil=[100,100,100,100], nl=[1,1,0,0], hid=[]):
    # Note the number of elements in fil list (macrolayers) should be the same in nl list
    # hid can be [] while if the are elements, additional dense layers are added in the output classifier

    csize=3; stri=2; psiz=4; pad='same';
    drop1=0.6  # Best value for CIFAR-100 after tuning in range 0.25 - 0.75 !

    nfilmax=np.shape(np.array(fil))[0]
    model = Sequential()
    # First macrolayer - connected to input  ----------------
    layer=0
    if nl[layer]>0:
        model.add(Conv2D(fil[layer], padding=pad, kernel_size=(csize, csize), input_shape=input_shape ) )
        model.add(Activation('relu'))
        for nonlin in range(1,nl[0]):
            model.add(Conv2D(fil[layer], padding=pad, kernel_size=(csize, csize)) )
            model.add(Activation('relu'))

        model.add(Conv2D(fil[0], padding=pad, kernel_size=(csize, csize) ) )
        model.add(BatchNormalization())
        model.add(MaxPooling2D(pool_size=(psiz, psiz),strides=(stri,stri),padding=pad))
        model.add(Dropout(drop1))

    else:
        model.add(Conv2D(fil[0], padding=pad, kernel_size=(csize, csize), input_shape=input_shape ) )
        model.add(BatchNormalization())
        model.add(MaxPooling2D(pool_size=(psiz, psiz),strides=(stri,stri),padding=pad))
        model.add(Dropout(drop1))
    # The remaining  macro-layers

    for layer in range(1,nfilmax):
        #------------------ nonlin layers -----------------
        for nonlin in range(nl[layer]):
            model.add(Conv2D(fil[layer], padding=pad, kernel_size=(csize, csize)) )
            model.add(Activation('relu'))

        #----------------- default macrolayer output

        model.add(Conv2D(fil[layer], padding=pad, kernel_size=(csize, csize)) )
        model.add(BatchNormalization())
        model.add(MaxPooling2D(pool_size=(psiz, psiz),strides=(stri,stri),padding=pad))
        model.add(Dropout(drop1))

    # Exit classifier
    # INPUT TO DENSE LAYER (FLATTEN - more data can overfit / GLOBAL - less data - may be a good choice )
    if flat==1:
        model.add(Flatten())  # alternanta cu GlobalAv ..
    elif flat==0:
        model.add(GlobalAveragePooling2D()) # pare sa fie mai Ok la cifar
    nhid=np.shape(np.array(hid))[0]
    if nhid>0:
        for lay in range(nhid):
            model.add(Dense(hid[lay], activation='relu'))
            #model.add(Dropout(drop1))
    model.add(Dense(num_classes, activation='softmax'))

# END OF MODEL DESCRIPTION
    model.compile(
        optimizer=tf.keras.optimizers.Adam(),
        loss = 'categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

# creare model

num_classes=50
model=create_v_cnn_model(input_shape, num_classes, flat=0,
                         fil=[32, 64,128], nl=[1,1,0], hid=[50])
model.summary()


	Modelul MobileNetV2

num_classes=50
def create_model():
  
pretrained_model = tf.keras.applications.MobileNetV2(alpha=0.75,   
			input_shape=[input_shape[0], input_shape[1], 3], include_top=False)
  pretrained_model.trainable = True   
  # True - all weights are trained; False: only the output layer is trained 

  model = tf.keras.Sequential([
    pretrained_model,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(num_classes, activation='softmax')
  ])
  myopt = Adam()

  # --------------------------   LOSS function  ------------------------------------
  my_loss='categorical_crossentropy'
  model.compile(loss=my_loss, 
              optimizer=myopt,   
              metrics=['accuracy'])
  return model

model = create_model()
model.summary()

	Modelul EfficientNetB0
      
!pip install -U --pre efficientnet

import efficientnet.tfkeras as efn
def get_efficientNet_model():
    enet = efn.EfficientNetB0(
        input_shape=input_shape,
        weights='noisy-student',
        include_top=False,
    )
    model = tf.keras.Sequential([
        enet,
        tf.keras.layers.GlobalAveragePooling2D(),
        tf.keras.layers.Dense(num_classes, activation='softmax')
    ])

    return model

num_classes = 50
input_shape=(32,32,3)
model = get_efficientNet_model()
optimizer_ft = tf.keras.optimizers.Adam(learning_rate=1e-5)
    # Compile the Model
model.compile(
        optimizer='adam',
        loss = 'categorical_crossentropy',
        metrics=['accuracy'],
    )
model.summary()


	Modelul ShuffleNet

def channel_split(x, name=''):
    in_channels = x.shape[-1]
    ip = in_channels // 2
    c_hat = Lambda(lambda z: z[:, :, :, :ip], name=f'{name}_sp0_slice')(x)  
    c = Lambda(lambda z: z[:, :, :, ip:], name=f'{name}_sp1_slice')(x)  
    return c_hat, c
def channel_shuffle(x):
    height, width, channels = x.shape.as_list()[1:]
    channels_per_split = channels // 2
    x = K.reshape(x, [-1, height, width, 2, channels_per_split])
    x = K.permute_dimensions(x, (0,1,2,4,3))
    x = K.reshape(x, [-1, height, width, channels])
    return x
def shuffle_unit(inputs, out_channels, bottleneck_ratio, strides=2, stage=1, block=1):
    bn_axis = -1  # Always use channels_last
    prefix = f'stage{stage}_block{block}' 
    bottleneck_channels = int(out_channels * bottleneck_ratio)
    if strides < 2:
        c_hat, c = channel_split(inputs, f'{prefix}_spl')
        inputs = c

    x = Conv2D(bottleneck_channels, kernel_size=(1, 1), strides=1, padding='same', name=f'{prefix}_1x1conv_1')(inputs)
    x = BatchNormalization(axis=bn_axis, name=f'{prefix}_bn_1x1conv_1')(x)
    x = Activation('relu', name=f'{prefix}_relu_1x1conv_1')(x)
    x = DepthwiseConv2D(kernel_size=3, strides=strides, padding='same', name=f'{prefix}_3x3dwconv')(x)
    x = BatchNormalization(axis=bn_axis, name=f'{prefix}_bn_3x3dwconv')(x)
    x = Conv2D(bottleneck_channels, kernel_size=1, strides=1, padding='same', name=f'{prefix}_1x1conv_2')(x)
    x = BatchNormalization(axis=bn_axis, name=f'{prefix}_bn_1x1conv_2')(x)
    x = Activation('relu', name=f'{prefix}_relu_1x1conv_2')(x)

    if strides < 2:
        ret = Concatenate(axis=bn_axis, name=f'{prefix}_concat_1')([x, c_hat])
    else:
        s2 = DepthwiseConv2D(kernel_size=3, strides=2, padding='same', name=f'{prefix}_3x3dwconv_2')(inputs)
        s2 = BatchNormalization(axis=bn_axis, name=f'{prefix}_bn_3x3dwconv_2')(s2)
        s2 = Conv2D(bottleneck_channels, kernel_size=1, strides=1, padding='same', name=f'{prefix}_1x1_conv_3')(s2)
        s2 = BatchNormalization(axis=bn_axis, name=f'{prefix}_bn_1x1conv_3')(s2)
        s2 = Activation('relu', name=f'{prefix}_relu_1x1conv_3')(s2)
        ret = Concatenate(axis=bn_axis, name=f'{prefix}_concat_2')([x, s2])

    ret = Lambda(channel_shuffle, name=f'{prefix}_channel_shuffle')(ret)
    return ret


def block(x, channel_map, bottleneck_ratio, repeat=1, stage=1):
    x = shuffle_unit(x, out_channels=channel_map[stage-1], strides=2, bottleneck_ratio=bottleneck_ratio, stage=stage, block=1)
    for i in range(1, repeat+1):
        x = shuffle_unit(x, out_channels=channel_map[stage-1], strides=1, bottleneck_ratio=bottleneck_ratio, stage=stage, block=(1+i))
    return x

def ShuffleNetV2(include_top=True, input_tensor=None, scale_factor=1.0, pooling='max', input_shape=(32,32,3), load_model=None, num_shuffle_units=[3,7,3], bottleneck_ratio=1, classes=50):
    if K.backend() != 'tensorflow':
        raise RuntimeError('Only TensorFlow backend is supported.')
    name = f'ShuffleNetV2_{scale_factor}_{bottleneck_ratio}_{"_".join([str(x) for x in num_shuffle_units])}'
    img_input = Input(shape=input_shape) if input_tensor is None else input_tensor

    # ShuffleNetV2 architecture code...
    x = Conv2D(24, kernel_size=(3, 3), padding='same', use_bias=False, strides=(2, 2), activation='relu', name='conv1')(img_input)
    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same', name='maxpool1')(x)

    out_channels_in_stage = [24, 48, 96, 192, 1024]  # Example channel layout, adjust based on your model's architecture

    for stage in range(0, len(num_shuffle_units)):
        repeat = num_shuffle_units[stage]
        x = block(x, out_channels_in_stage, bottleneck_ratio=bottleneck_ratio, repeat=repeat, stage=stage + 1)

    if pooling == 'avg':
        x = GlobalAveragePooling2D(name='global_avg_pool')(x)
    elif pooling == 'max':
        x = GlobalMaxPooling2D(name='global_max_pool')(x)

    if include_top:
        x = Dense(classes, activation='softmax', name='fc')(x)

    model = Model(img_input, x, name=name)

    if load_model is not None:
        model.load_weights(load_model)

    return model

model = ShuffleNetV2(include_top=True, input_shape=(32, 32, 3),load_model=None, classes=50)
model.compile(loss='categorical_crossentropy', 
              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
              metrics=['accuracy'])
print(model.summary())

	Codul pentru antrenarea modelelor

from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard
from keras.models import load_model
import time as ti

checkpoint = ModelCheckpoint('initial_model.keras', monitor= 'val_accuracy',
                             mode= 'max', save_best_only = True, verbose=1)
reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=3, verbose=1)
epoci = 17
t1=ti.time()

history = model.fit(
    x_train, y_train, 
    epochs=epoci, 
    validation_data=(x_val, y_val), 
    batch_size=100, 
    verbose=1,
    callbacks = [checkpoint, reduce_lr])

t2=ti.time()
print('====================================================')
print('Training with  ',epoci,' epochs, lasted  ',int(t2-t1)/60,' minutes')
t1=ti.time()

model=load_model('initial_model.keras')
bp=model.get_weights()  # best weights set
score = model.evaluate(x_val, y_val, verbose=0)
t2=ti.time()
print ('Total number of parameters: ',model.count_params())
print('Best validation accuracy :', 100*score[1],'%')
#print ('Timp predictie pe tot setul de test: ',t2-t1)
print('Latency - GPU (per sample):', 1000*(t2-t1)/np.shape(x_val)[0], 'ms')

	Afișarea graficelor de acuratețe și pierdere pentru antrenare și validare

from matplotlib import pyplot as plt
def display_training_curves(training, validation, title, subplot):
    if subplot%10==1: # set up the subplots on the first call
        plt.subplots(figsize=(7,3), facecolor='#F0F0F0')
        plt.tight_layout()
    ax = plt.subplot(subplot)
    ax.set_facecolor('#F8F8F8')
    ax.plot(training)
    ax.plot(validation)
    ax.set_title('model '+ title)
    ax.set_ylabel(title)
    ax.set_xlabel('epoch')
    ax.legend(['train', 'valid.'])
display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 121)
display_training_curves(history.history['accuracy'], 
                        history.history['val_accuracy'], 'accuracy', 122)



# Anexa 2

	Convertirea modelelor în format .tflite

model=load_model('model.keras') # modelul obținut în urma antrenării sau alt model salvat
converter = tf.lite.TFLiteConverter.from_keras_model(model)
t1=ti.time()
tflite_model = converter.convert()
t2=ti.time()
print('Durata conversie: ', t2-t1,' secunde')
open("model.tflite", "wb").write(tflite_model)

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_types = [tf.float16]

t1=ti.time()
quantized_tflite_model = converter.convert()
t2=ti.time()
print('Durata conversie: ', t2-t1,' secunde')
open("model_quant.tflite", "wb").write(quantized_tflite_model)



	Evaluarea modelelor după convertire


# "Helper" pentru evaluarea acuratetii pe modelul .tflite
#--------------------------------------------------------------------
# Se ruleaza o data - util pentru a prezice acuratetea
# adaptat dupa: https://www.tensorflow.org/lite/performance/post_training_quant
# Copyright Radu Dogaru, May 2024 radu.dogaru@upb.ro
#
import time as ti
from sklearn.metrics import classification_report, confusion_matrix
import tensorflow as tf

num_classes=50
datagen=False ; out_coding='cat' 
# functie pentru conversia din format datagen in x_train x_test
# se preiau un numar bine precizat de "batch-uri"
# Copyright Radu Dogaru, 1 June 2024
#------------------------------------------------------------
def conv_tensor(datagen, num_batches):
    for x_val, y_val in datagen:
            break;
    for b in range(num_batches-1):
        for x, y in datagen:
            break;
        x_val= tf.concat([x_val, x], axis=0)
        y_val= tf.concat([y_val, y], axis=0)
    return x_val, y_val



# A helper function to evaluate the TF Lite model using "test" dataset.
def evaluate_model(interpreter, num_batches, x_val, y_val):  # num_batches only if you use validation_generator
  if datagen==True:
    # prepare some x_test y_test data for num_batches
    x_val,y_val=conv_tensor(datagen=test_generator, num_batches=num_batches)
  #print('xxxxxxxx',np.shape(y_test))
  if out_coding=='non':
        ync_val=y_val
  else:
        ync_val=np.int16(np.dot(y_val,np.array(range(num_classes))))
  input_index = interpreter.get_input_details()[0]["index"]
  output_index = interpreter.get_output_details()[0]["index"]
  #print('oinx: ', output_index)
  # Run predictions on every image in the "test" dataset.
  prediction_digits = []
  durata=0
  for val_image in x_val:
    # Pre-processing: add batch dimension and convert to float32 to match with
    # the model's input data format.
    #print(np.shape(test_image))
    val_image = np.expand_dims(val_image, axis=0).astype(np.float32) # * 255 # comentat
    #print(np.shape(test_image))
    interpreter.set_tensor(input_index, val_image)
    t1=ti.time()
    # Run inference.
    interpreter.invoke()
    t2=ti.time()
    durata += (t2-t1)
    # Post-processing: remove batch dimension and find the digit with highest
    # probability.
    output = interpreter.get_tensor(output_index)  # s-a modificat la get_tensor (varianta tensor nu mai este actuala !!!)
    #print('Output: ',output)
    digit = np.argmax(output, axis=1)  # si aici s-a modificat de la output()[0]
    #print('digite=',digit)
    prediction_digits.append(digit)

  # Compare prediction results with ground truth labels to calculate accuracy.
  accurate_count = 0
  for index in range(len(prediction_digits)):
    if prediction_digits[index] == ync_val[index]:
      accurate_count += 1
  accuracy = accurate_count * 1.0 / len(prediction_digits)
  C=confusion_matrix(prediction_digits,ync_val)  # matricea de confuzie pe model .tflite
  print(C)
  print(classification_report(ync_val, prediction_digits ))
  return accuracy, prediction_digits, 1000*durata/len(prediction_digits)


# se încarcă modelul în interpretor
interpreter = tf.lite.Interpreter(
model_path='/kaggle/input/c-nn_emnist/tflite/enn-emnist/1/V-CNN_emnsit_quant.tflite' )  # se alege calea către modelul dorit
interpreter.allocate_tensors()

datagen=False ; out_coding='cat'  # s-a lucrat cu datagen si format ;sparse;
# num_bathes se alege astfel incat sa avem un numar mare de esantioane pentru evaluare
# numar de esantioane este num_batches*train_batch
# un numar prea mare poate duce la dep. de memorie !!
# Daca datagen=False num_batches nu conteaza
# Daca datagen=True se pot alege x_test=[], y_test=[]

acc, pred, lat = evaluate_model(interpreter, num_batches=4, x_val=x_val, y_val=y_val)
print('Acuratetea pe modelul .tflite este de', 100*acc,'%', 'Latenta: ',lat,' ms')

